#!/usr/bin/env python3
"""
Obsidian Knowledge Assistant - Quality Scoring Tool
ç‹¬ç«‹çš„ç¬”è®°è´¨é‡è¯„åˆ†å·¥å…·
"""

import os
import sys
import argparse
from pathlib import Path
import sys

# æ·»åŠ  src ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from core.analyzer import ObsidianAnalyzer
from core.quality_scorer import QualityScorer, QualityScore


def display_score_details(score: QualityScore):
    """æ˜¾ç¤ºå•ä¸ªç¬”è®°çš„è¯¦ç»†è¯„åˆ†"""
    print(f"\n{'='*60}")
    print(f"  ğŸ“ {score.note_name}")
    print(f"{'='*60}")
    print(f"  æ€»åˆ†: {score.percentage:.1f}/100 (è¯„çº§: {score.grade})")
    print()
    print("  å„ç»´åº¦å¾—åˆ†:")
    print(f"    å­—æ•°:   {score.word_count_score:>5.1f}/100")
    print(f"    é“¾æ¥:   {score.link_score:>5.1f}/100")
    print(f"    æ ‡ç­¾:   {score.tag_score:>5.1f}/100")
    print(f"    æ–°é²œåº¦: {score.freshness_score:>5.1f}/100")

    if score.issues:
        print()
        print("  âŒ å­˜åœ¨é—®é¢˜:")
        for issue in score.issues:
            print(f"    â€¢ {issue}")

    if score.suggestions:
        print()
        print("  ğŸ’¡ æ”¹è¿›å»ºè®®:")
        for suggestion in score.suggestions:
            print(f"    â€¢ {suggestion}")

    print(f"{'='*60}")


def list_by_score(scores: dict, args):
    """æŒ‰åˆ†æ•°åˆ—å‡ºç¬”è®°"""
    sorted_scores = sorted(
        scores.values(), key=lambda x: x.percentage, reverse=not args.ascending
    )

    if args.limit:
        sorted_scores = sorted_scores[: args.limit]

    if args.grade:
        sorted_scores = [s for s in sorted_scores if s.grade == args.grade.upper()]

    print(f"\n{'='*60}")
    print(f"  ğŸ“Š ç¬”è®°è´¨é‡æ’å")
    print(f"{'='*60}")
    print()

    for i, score in enumerate(sorted_scores, 1):
        print(f"{i:3}. [{score.grade}] {score.note_name}")
        print(
            f"     åˆ†æ•°: {score.percentage:.1f}  |  å­—æ•°:{score.word_count_score:.0f}  é“¾æ¥:{score.link_score:.0f}  æ ‡ç­¾:{score.tag_score:.0f}  æ–°é²œ:{score.freshness_score:.0f}"
        )
        print()


def show_statistics(stats: dict):
    """æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯"""
    print(f"\n{'='*60}")
    print(f"  ğŸ“Š è´¨é‡ç»Ÿè®¡")
    print(f"{'='*60}")
    print(f"  æ€»ç¬”è®°æ•°:  {stats['total_notes']}")
    print(f"  å¹³å‡åˆ†:    {stats['average_score']:.1f}")
    print(f"  ä¸­ä½æ•°:    {stats['median_score']:.1f}")
    print(f"  æœ€é«˜åˆ†:    {stats['max_score']:.1f}")
    print(f"  æœ€ä½åˆ†:    {stats['min_score']:.1f}")
    print()
    print("  è¯„çº§åˆ†å¸ƒ:")

    grade_dist = stats["grade_distribution"]
    total = stats["total_notes"]

    for grade in ["A", "B", "C", "D", "F"]:
        count = grade_dist[grade]
        percentage = (count / total * 100) if total > 0 else 0
        bar = "â–ˆ" * int(percentage / 2)
        print(f"    {grade}: {count:3} ({percentage:5.1f}%) {bar}")

    print(f"{'='*60}")


def show_needs_improvement(stats: dict, limit: int = 10):
    """æ˜¾ç¤ºéœ€è¦æ”¹è¿›çš„ç¬”è®°"""
    needs_improvement = stats["needs_improvement"][:limit]

    print(f"\n{'='*60}")
    print(f"  âš ï¸  éœ€è¦æ”¹è¿›çš„ç¬”è®° (Top {min(limit, len(stats['needs_improvement']))})")
    print(f"{'='*60}")
    print()

    for i, score in enumerate(needs_improvement, 1):
        print(f"{i}. {score.note_name} - {score.percentage:.1f}åˆ† ({score.grade})")

        if score.issues:
            for issue in score.issues[:2]:  # åªæ˜¾ç¤ºå‰2ä¸ªé—®é¢˜
                print(f"   âŒ {issue}")

        print()


def show_excellent(stats: dict, limit: int = 10):
    """æ˜¾ç¤ºä¼˜è´¨ç¬”è®°"""
    excellent = stats["excellent_notes"][:limit]

    print(f"\n{'='*60}")
    print(f"  â­ ä¼˜è´¨ç¬”è®° (Top {min(limit, len(stats['excellent_notes']))})")
    print(f"{'='*60}")
    print()

    for i, score in enumerate(excellent, 1):
        print(f"{i}. {score.note_name} - {score.percentage:.1f}åˆ† ({score.grade})")
        print(
            f"   å­—æ•°:{score.word_count_score:.0f}  é“¾æ¥:{score.link_score:.0f}  æ ‡ç­¾:{score.tag_score:.0f}  æ–°é²œ:{score.freshness_score:.0f}"
        )
        print()


def check_note(scores: dict, note_name: str):
    """æ£€æŸ¥ç‰¹å®šç¬”è®°çš„è¯„åˆ†"""
    # å°è¯•ç²¾ç¡®åŒ¹é…
    if note_name in scores:
        display_score_details(scores[note_name])
        return

    # å°è¯•æ¨¡ç³ŠåŒ¹é…
    matches = [name for name in scores.keys() if note_name.lower() in name.lower()]

    if not matches:
        print(f"\nâŒ æœªæ‰¾åˆ°ç¬”è®°: {note_name}")
        return

    if len(matches) == 1:
        display_score_details(scores[matches[0]])
    else:
        print(f"\næ‰¾åˆ° {len(matches)} ä¸ªåŒ¹é…çš„ç¬”è®°:")
        for i, match in enumerate(matches[:10], 1):
            print(
                f"{i}. {match} - {scores[match].percentage:.1f}åˆ† ({scores[match].grade})"
            )


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="Obsidian Knowledge Assistant - Quality Scoring Tool",
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )

    parser.add_argument(
        "--vault", type=str, help="Vault path (overrides VAULT_PATH env var)"
    )

    subparsers = parser.add_subparsers(dest="command", help="Commands")

    # score å‘½ä»¤
    score_parser = subparsers.add_parser("score", help="Score all notes")

    # list å‘½ä»¤
    list_parser = subparsers.add_parser("list", help="List notes by score")
    list_parser.add_argument("--limit", type=int, default=20, help="Limit results")
    list_parser.add_argument(
        "--grade", type=str, choices=["A", "B", "C", "D", "F"], help="Filter by grade"
    )
    list_parser.add_argument(
        "--ascending", action="store_true", help="Sort ascending (low to high)"
    )

    # stats å‘½ä»¤
    stats_parser = subparsers.add_parser("stats", help="Show quality statistics")

    # worst å‘½ä»¤
    worst_parser = subparsers.add_parser("worst", help="Show worst notes")
    worst_parser.add_argument(
        "--limit", type=int, default=10, help="Number of notes to show"
    )

    # best å‘½ä»¤
    best_parser = subparsers.add_parser("best", help="Show best notes")
    best_parser.add_argument(
        "--limit", type=int, default=10, help="Number of notes to show"
    )

    # check å‘½ä»¤
    check_parser = subparsers.add_parser("check", help="Check specific note")
    check_parser.add_argument("note_name", help="Note name to check")

    args = parser.parse_args()

    # è·å– vault è·¯å¾„
    vault_path = args.vault or os.getenv("VAULT_PATH")
    if not vault_path:
        print("âŒ Error: Vault path not specified")
        print("   Use --vault or set VAULT_PATH environment variable")
        sys.exit(1)

    vault_path = Path(vault_path)
    if not vault_path.exists():
        print(f"âŒ Error: Vault does not exist: {vault_path}")
        sys.exit(1)

    # åŠ è½½é…ç½®
    exclude_folders = os.getenv("EXCLUDE_FOLDERS", ".obsidian,.trash").split(",")
    exclude_notes = (
        os.getenv("EXCLUDE_NOTES", "").split(",") if os.getenv("EXCLUDE_NOTES") else []
    )

    # åˆ›å»ºåˆ†æå™¨
    print(f"ğŸ” Loading vault: {vault_path}")
    analyzer = ObsidianAnalyzer(str(vault_path), exclude_folders, exclude_notes)
    analyzer.scan_vault()

    # è®¡ç®—è´¨é‡è¯„åˆ†
    print("ğŸ¯ Calculating quality scores...")
    scorer = QualityScorer(analyzer.notes)
    scores = scorer.score_all_notes()
    stats = scorer.get_statistics(scores)

    # æ‰§è¡Œå‘½ä»¤
    if args.command == "score" or args.command is None:
        show_statistics(stats)
        print()
        show_excellent(stats, 5)
        print()
        show_needs_improvement(stats, 5)

    elif args.command == "list":
        list_by_score(scores, args)

    elif args.command == "stats":
        show_statistics(stats)

    elif args.command == "worst":
        show_needs_improvement(stats, args.limit)

    elif args.command == "best":
        show_excellent(stats, args.limit)

    elif args.command == "check":
        check_note(scores, args.note_name)

    else:
        parser.print_help()


if __name__ == "__main__":
    main()
